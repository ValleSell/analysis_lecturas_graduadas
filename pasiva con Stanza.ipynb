{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "142e8b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "import spacy_stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb394d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7d05c7028642a7ae1d9ffd38febd9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-14 11:10:24 INFO: Downloading default packages for language: es (Spanish)...\n",
      "2022-02-14 11:10:26 INFO: File exists: C:\\Users\\valle\\stanza_resources\\es\\default.zip.\n",
      "2022-02-14 11:10:30 INFO: Finished downloading models and saved to C:\\Users\\valle\\stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "stanza.download(\"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d44deda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-24 11:15:38 INFO: Loading these models for language: es (Spanish):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ancora  |\n",
      "| mwt       | ancora  |\n",
      "| pos       | ancora  |\n",
      "| lemma     | ancora  |\n",
      "| depparse  | ancora  |\n",
      "| ner       | conll02 |\n",
      "=======================\n",
      "\n",
      "2022-02-24 11:15:38 INFO: Use device: cpu\n",
      "2022-02-24 11:15:38 INFO: Loading: tokenize\n",
      "2022-02-24 11:15:38 INFO: Loading: mwt\n",
      "2022-02-24 11:15:38 INFO: Loading: pos\n",
      "2022-02-24 11:15:38 INFO: Loading: lemma\n",
      "2022-02-24 11:15:38 INFO: Loading: depparse\n",
      "2022-02-24 11:15:39 INFO: Loading: ner\n",
      "2022-02-24 11:15:40 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the pipeline\n",
    "nlp = spacy_stanza.load_pipeline(\"es\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa83d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "José José PROPN nsubj PER\n",
      "ha haber AUX aux \n",
      "sido ser AUX aux \n",
      "arrestado arrestar VERB root \n",
      "por por ADP case \n",
      "la el DET det \n",
      "policía policía NOUN obj \n",
      ". . PUNCT punct \n",
      "(José,)\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"José ha sido arrestado por la policía.\")\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.dep_, token.ent_type_)\n",
    "print(doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c13acc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-24 11:23:03 INFO: Loading these models for language: es (Spanish):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ancora  |\n",
      "| mwt       | ancora  |\n",
      "| pos       | ancora  |\n",
      "| lemma     | ancora  |\n",
      "| depparse  | ancora  |\n",
      "=======================\n",
      "\n",
      "2022-02-24 11:23:03 INFO: Use device: cpu\n",
      "2022-02-24 11:23:03 INFO: Loading: tokenize\n",
      "2022-02-24 11:23:03 INFO: Loading: mwt\n",
      "2022-02-24 11:23:03 INFO: Loading: pos\n",
      "2022-02-24 11:23:03 INFO: Loading: lemma\n",
      "2022-02-24 11:23:03 INFO: Loading: depparse\n",
      "2022-02-24 11:23:03 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: José\thead id: 4\thead: arrestado\tdeprel: nsubj\n",
      "id: 2\tword: ha\thead id: 4\thead: arrestado\tdeprel: aux\n",
      "id: 3\tword: sido\thead id: 4\thead: arrestado\tdeprel: aux\n",
      "id: 4\tword: arrestado\thead id: 0\thead: root\tdeprel: root\n",
      "id: 5\tword: por\thead id: 7\thead: policía\tdeprel: case\n",
      "id: 6\tword: la\thead id: 7\thead: policía\tdeprel: det\n",
      "id: 7\tword: policía\thead id: 4\thead: arrestado\tdeprel: obj\n",
      "id: 8\tword: .\thead id: 4\thead: arrestado\tdeprel: punct\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='es', processors='tokenize,mwt,pos,lemma,depparse')\n",
    "doc = nlp('José ha sido arrestado por la policía.')\n",
    "print(*[f'id: {word.id}\\tword: {word.text}\\thead id: {word.head}\\thead: {sent.words[word.head-1].text if word.head > 0 else \"root\"}\\tdeprel: {word.deprel}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f5bb56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d57af867334335947683add8d6df0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.3.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-24 11:20:48 INFO: Downloading default packages for language: en (English)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0342ceb9c95b421da4eff7711d839217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.3.0/models/default.zip:   0%|          | 0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-24 11:21:30 INFO: Finished downloading models and saved to C:\\Users\\valle\\stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "stanza.download(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ba78f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-24 11:21:47 INFO: Loading these models for language: en (English):\n",
      "============================\n",
      "| Processor    | Package   |\n",
      "----------------------------\n",
      "| tokenize     | combined  |\n",
      "| pos          | combined  |\n",
      "| lemma        | combined  |\n",
      "| depparse     | combined  |\n",
      "| sentiment    | sstplus   |\n",
      "| constituency | wsj       |\n",
      "| ner          | ontonotes |\n",
      "============================\n",
      "\n",
      "2022-02-24 11:21:47 INFO: Use device: cpu\n",
      "2022-02-24 11:21:47 INFO: Loading: tokenize\n",
      "2022-02-24 11:21:47 INFO: Loading: pos\n",
      "2022-02-24 11:21:48 INFO: Loading: lemma\n",
      "2022-02-24 11:21:48 INFO: Loading: depparse\n",
      "2022-02-24 11:21:48 INFO: Loading: sentiment\n",
      "2022-02-24 11:21:48 INFO: Loading: constituency\n",
      "2022-02-24 11:21:49 INFO: Loading: ner\n",
      "2022-02-24 11:21:50 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the pipeline\n",
    "nlp = spacy_stanza.load_pipeline(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "710ad2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-24 11:21:54 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2022-02-24 11:21:54 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| pos       | combined |\n",
      "| lemma     | combined |\n",
      "| depparse  | combined |\n",
      "========================\n",
      "\n",
      "2022-02-24 11:21:54 INFO: Use device: cpu\n",
      "2022-02-24 11:21:54 INFO: Loading: tokenize\n",
      "2022-02-24 11:21:54 INFO: Loading: pos\n",
      "2022-02-24 11:21:54 INFO: Loading: lemma\n",
      "2022-02-24 11:21:54 INFO: Loading: depparse\n",
      "2022-02-24 11:21:55 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\tword: José\thead id: 4\thead: arrested\tdeprel: nsubj:pass\n",
      "id: 2\tword: has\thead id: 4\thead: arrested\tdeprel: aux\n",
      "id: 3\tword: been\thead id: 4\thead: arrested\tdeprel: aux:pass\n",
      "id: 4\tword: arrested\thead id: 0\thead: root\tdeprel: root\n",
      "id: 5\tword: by\thead id: 7\thead: police\tdeprel: case\n",
      "id: 6\tword: the\thead id: 7\thead: police\tdeprel: det\n",
      "id: 7\tword: police\thead id: 4\thead: arrested\tdeprel: obl\n",
      "id: 8\tword: .\thead id: 4\thead: arrested\tdeprel: punct\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,mwt,pos,lemma,depparse')\n",
    "doc = nlp('José has been arrested by the police.')\n",
    "print(*[f'id: {word.id}\\tword: {word.text}\\thead id: {word.head}\\thead: {sent.words[word.head-1].text if word.head > 0 else \"root\"}\\tdeprel: {word.deprel}' for sent in doc.sentences for word in sent.words], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2717b379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
